{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea633f13",
   "metadata": {},
   "source": [
    "# **Milestone 2: Data Ingestion Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b373f663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from: ./archive (6)/dynamic_pricing.csv Shape: (1000, 10)\n",
      "Data cleaned successfully\n",
      "Final shape after cleaning: (990, 10)\n",
      "Pipeline completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#data ingestion pipeline using pandas, checked for both raw and processed data\n",
    "#raw data stored in input file path and processed data in the output file\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Config: input/output filenames (will try fallbacks if INPUT_FILE not found)\n",
    "INPUT_FILE = \"dynamic_pricing.csv\"\n",
    "OUTPUT_FILE = \"cleaned_csv_data.csv\"\n",
    "FALLBACK_INPUTS = [INPUT_FILE, \"./archive (6)/dynamic_pricing.csv\", \"dynamic_pricing_cleaned.csv\"]\n",
    "\n",
    "def find_existing_file(candidates):\n",
    "    for p in candidates:\n",
    "        if os.path.isfile(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def load_data(file_path):\n",
    "    # allow passing None and try fallbacks\n",
    "    path = file_path if file_path and os.path.isfile(file_path) else find_existing_file(FALLBACK_INPUTS)\n",
    "    if path is None:\n",
    "        raise FileNotFoundError(f\"No input file found. Tried: {file_path} and fallbacks: {FALLBACK_INPUTS}\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Data loaded from:\", path, \"Shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "def normalize_column_names(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    return df\n",
    "\n",
    "def safe_label_encode(series, max_unique=200):\n",
    "    # guard against huge-cardinality encoding that can be harmful\n",
    "    s = series.fillna('missing').astype(str)\n",
    "    uniques = s.nunique()\n",
    "    if uniques > max_unique:\n",
    "        print(f\"Skipping label-encoding for column with high cardinality ({uniques} uniques).\")\n",
    "        return s\n",
    "    return LabelEncoder().fit_transform(s)\n",
    "\n",
    "def remove_outliers_iqr(df, col):\n",
    "    # only remove outliers when there are enough distinct values\n",
    "    if df[col].nunique() < 3:\n",
    "        return df\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    if pd.isna(IQR) or IQR == 0:\n",
    "        return df\n",
    "    mask = ~((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)))\n",
    "    return df.loc[mask]\n",
    "\n",
    "def clean_data(df, drop_na_threshold=0.0):\n",
    "    # Normalize column names early\n",
    "    df = normalize_column_names(df)\n",
    "\n",
    "    # Optionally drop columns or rows with too many missing values (threshold on rows is 0 by default)\n",
    "    if drop_na_threshold > 0:\n",
    "        df = df.dropna(thresh=int((1 - drop_na_threshold) * len(df.columns)), axis=1)\n",
    "    # drop rows with all-NaN\n",
    "    df = df.dropna(how='all')\n",
    "\n",
    "    # Separate column types\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Fill missing values: numeric -> median, categorical -> 'missing'\n",
    "    for col in numeric_cols:\n",
    "        median = df[col].median()\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df[col] = df[col].fillna(median)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype(str).fillna('missing').str.strip()\n",
    "\n",
    "    # Remove outliers for numeric cols (safely)\n",
    "    for col in numeric_cols:\n",
    "        try:\n",
    "            df = remove_outliers_iqr(df, col)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping outlier removal on {col}: {e}\")\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Label-encode categorical columns (safely)\n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            df[col] = safe_label_encode(df[col])\n",
    "        except Exception as e:\n",
    "            print(f\"Could not label-encode {col}: {e}\")\n",
    "\n",
    "    print(\"Data cleaned successfully\")\n",
    "    print(\"Final shape after cleaning:\", df.shape)\n",
    "    return df\n",
    "\n",
    "def run_pipeline(input_file=INPUT_FILE, output_file=OUTPUT_FILE):\n",
    "    df_raw = load_data(input_file)\n",
    "    df_cleaned = clean_data(df_raw)\n",
    "    print(\"Pipeline completed successfully.\")\n",
    "    return df_cleaned\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_cleaned = run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "636fff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      revenue  profit_margin  conversion_rate  revenue_lift_pct\n",
      "0  284.257273           30.0              0.0          0.000000\n",
      "1  173.874753           30.0              0.0        -38.831907\n",
      "2  329.795469           30.0              0.0         16.020064\n",
      "3  470.201232           30.0              0.0         65.413967\n",
      "4  579.681422           30.0              0.0        103.928440\n"
     ]
    }
   ],
   "source": [
    "# KPIs for Revenue lift, Profit Margin, Conversion Rate â€” robust version\n",
    "import pandas as pd\n",
    "\n",
    "def find_col(cols, candidates):\n",
    "    cols_l = [c.lower() for c in cols]\n",
    "    for cand in candidates:\n",
    "        for i, c in enumerate(cols_l):\n",
    "            if cand.lower() in c:\n",
    "                return cols[i]\n",
    "    return None\n",
    "\n",
    "# load cleaned data if present, else try the pipeline output\n",
    "if os.path.isfile('cleaned_csv_data.csv'):\n",
    "    df = pd.read_csv('cleaned_csv_data.csv')\n",
    "else:\n",
    "    # try fallback names or run pipeline\n",
    "    candidates = ['cleaned_csv_data.csv', 'baseline_threshold_pricing.csv', 'cleaned_dynamic_pricing.csv']\n",
    "    found = None\n",
    "    for p in candidates:\n",
    "        if os.path.isfile(p):\n",
    "            found = p\n",
    "            break\n",
    "    if found:\n",
    "        df = pd.read_csv(found)\n",
    "    else:\n",
    "        print('No cleaned CSV found; please run the ingestion pipeline first (run_pipeline).')\n",
    "        raise FileNotFoundError('cleaned_csv_data.csv not found')\n",
    "\n",
    "# normalize columns\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# detect revenue-like and loyalty-like columns\n",
    "revenue_col = find_col(df.columns, ['historical_cost_of_ride', 'historical_cost', 'cost_of_ride', 'cost', 'fare'])\n",
    "loyalty_col = find_col(df.columns, ['customer_loyalty_status', 'customer_loyalty', 'loyalty_status', 'loyalty'])\n",
    "\n",
    "if revenue_col is None:\n",
    "    raise KeyError('No revenue-like column found. Available columns: ' + ','.join(df.columns))\n",
    "\n",
    "# ensure numeric\n",
    "df[revenue_col] = pd.to_numeric(df[revenue_col], errors='coerce').fillna(0)\n",
    "df['revenue'] = df[revenue_col]\n",
    "df['profit'] = df['revenue'] * 0.3\n",
    "df['profit_margin'] = (df['profit'] / df['revenue']).replace([float('inf'), -float('inf')], 0).fillna(0) * 100\n",
    "\n",
    "if loyalty_col is not None:\n",
    "    # coerce loyalty to numeric percentile-style conversion if possible\n",
    "    try:\n",
    "        df[loyalty_col] = pd.to_numeric(df[loyalty_col], errors='coerce')\n",
    "        df['conversion_rate'] = (df[loyalty_col] / df[loyalty_col].max()).fillna(0) * 100\n",
    "        \n",
    "    except Exception:\n",
    "        # fallback: treat loyalty as categorical frequency\n",
    "        df['conversion_rate'] = 0\n",
    "else:\n",
    "    df['conversion_rate'] = 0\n",
    "\n",
    "baseline_revenue = df['revenue'].iloc[0] if len(df) > 0 else 0\n",
    "df['revenue_lift_pct'] = ((df['revenue'] - baseline_revenue) / baseline_revenue).replace([float('inf'), -float('inf')], 0).fillna(0) * 100 if baseline_revenue != 0 else 0\n",
    "\n",
    "kpi_summary = df[['revenue', 'profit_margin', 'conversion_rate']].copy()\n",
    "kpi_summary['revenue_lift_pct'] = df['revenue_lift_pct'] if isinstance(df['revenue_lift_pct'], (pd.Series, list)) else [df['revenue_lift_pct']]\n",
    "print(kpi_summary.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PriceOptima)",
   "language": "python",
   "name": "priceoptima_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
