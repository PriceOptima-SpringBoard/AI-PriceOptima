{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5d566d",
   "metadata": {},
   "source": [
    "## Milestone 1: Requirements & Data Preparation\n",
    "\n",
    "###  Step 1: Data Loading and Initial Exploration\n",
    "\n",
    "As part of the **data ingestion and preparation phase**, it begin by importing the required Python libraries and loading the dataset for analysis.  \n",
    "The dataset is sourced from **Kaggle Dynamic Pricing Dataset** and **Statso Case Study**, containing historical sales, pricing, and inventory information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b478465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 10)\n",
      "\n",
      "Data Types:\n",
      " Number_of_Riders             int64\n",
      "Number_of_Drivers            int64\n",
      "Location_Category           object\n",
      "Customer_Loyalty_Status     object\n",
      "Number_of_Past_Rides         int64\n",
      "Average_Ratings            float64\n",
      "Time_of_Booking             object\n",
      "Vehicle_Type                object\n",
      "Expected_Ride_Duration       int64\n",
      "Historical_Cost_of_Ride    float64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "    Number_of_Riders  Number_of_Drivers Location_Category  \\\n",
      "0                90                 45             Urban   \n",
      "1                58                 39          Suburban   \n",
      "2                42                 31             Rural   \n",
      "3                89                 28             Rural   \n",
      "4                78                 22             Rural   \n",
      "\n",
      "  Customer_Loyalty_Status  Number_of_Past_Rides  Average_Ratings  \\\n",
      "0                  Silver                    13             4.47   \n",
      "1                  Silver                    72             4.06   \n",
      "2                  Silver                     0             3.99   \n",
      "3                 Regular                    67             4.31   \n",
      "4                 Regular                    74             3.77   \n",
      "\n",
      "  Time_of_Booking Vehicle_Type  Expected_Ride_Duration  \\\n",
      "0           Night      Premium                      90   \n",
      "1         Evening      Economy                      43   \n",
      "2       Afternoon      Premium                      76   \n",
      "3       Afternoon      Premium                     134   \n",
      "4       Afternoon      Economy                     149   \n",
      "\n",
      "   Historical_Cost_of_Ride  \n",
      "0               284.257273  \n",
      "1               173.874753  \n",
      "2               329.795469  \n",
      "3               470.201232  \n",
      "4               579.681422  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dynamic_pricing.csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nData Types:\\n\", df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e420984",
   "metadata": {},
   "source": [
    "### Milestone 1: Requirements & Data Preparation\n",
    "#### Step 3: Handle Categorical Variables (Encoding)\n",
    "\n",
    "Before model training, all categorical (text-based) features in the dataset must be converted into numerical form.\n",
    "This ensures that machine learning algorithms such as XGBoost, LightGBM, and other advanced models can process the data effectively.\n",
    "Encoding categorical variables is a crucial preprocessing step that directly supports later stages of Feature Engineering and Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6391fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Categorical variables encoded\n",
      "   Number_of_Riders  Number_of_Drivers  Location_Category  \\\n",
      "0                90                 45                  2   \n",
      "1                58                 39                  1   \n",
      "2                42                 31                  0   \n",
      "3                89                 28                  0   \n",
      "4                78                 22                  0   \n",
      "\n",
      "   Customer_Loyalty_Status  Number_of_Past_Rides  Average_Ratings  \\\n",
      "0                        2                    13             4.47   \n",
      "1                        2                    72             4.06   \n",
      "2                        2                     0             3.99   \n",
      "3                        1                    67             4.31   \n",
      "4                        1                    74             3.77   \n",
      "\n",
      "   Time_of_Booking  Vehicle_Type  Expected_Ride_Duration  \\\n",
      "0                3             1                      90   \n",
      "1                1             0                      43   \n",
      "2                0             1                      76   \n",
      "3                0             1                     134   \n",
      "4                0             0                     149   \n",
      "\n",
      "   Historical_Cost_of_Ride  \n",
      "0               284.257273  \n",
      "1               173.874753  \n",
      "2               329.795469  \n",
      "3               470.201232  \n",
      "4               579.681422  \n"
     ]
    }
   ],
   "source": [
    "#Handle categorical variables (Encoding)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dynamic_pricing.csv\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_enc = LabelEncoder()\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = label_enc.fit_transform(df[col])\n",
    "\n",
    "print(\" Categorical variables encoded\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774b4e1",
   "metadata": {},
   "source": [
    "### Milestone 1: Requirements & Data Preparation\n",
    "#### Step 4: Save Cleaned and Encoded Dataset\n",
    "\n",
    "After completing all data preprocessing steps — including missing value handling, encoding categorical features, and data validation — the cleaned dataset is saved for later use in feature engineering and model training.\n",
    "Saving the preprocessed data ensures reproducibility, traceability, and efficient workflow management throughout the AI: PriceOptima pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6835473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned dataset saved as 'cleaned_csv_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "df.to_csv(\"cleaned_csv_data.csv\", index=False)\n",
    "\n",
    "print(\" Cleaned dataset saved as 'cleaned_csv_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850dab6",
   "metadata": {},
   "source": [
    "### Milestone 1: Requirements & Data Preparation\n",
    "#### Step 5: Basic Data Loading and Cleaning Pipeline\n",
    "\n",
    "To ensure a standardized, reproducible data preparation process, a machine learning pipeline is constructed using Scikit-learn’s Pipeline and ColumnTransformer modules.\n",
    "This step automates the handling of missing values and scaling of numerical data, while ensuring categorical features are properly imputed for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c4e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline applied successfully!\n",
      "Processed data shape: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# a basic pipeline to load and clean data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),   # Fill missing numeric values\n",
    "    (\"scaler\", StandardScaler())                   # Scale numeric features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\"))  \n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(\"Pipeline applied successfully!\")\n",
    "print(\"Processed data shape:\", X_processed.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
