{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880ff282",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"text-align:center; color:darkgreen; font-family:Helvetica, Arial, sans-serif; font-weight:bold;\">\n",
    "Milestone 2 â€“ Data Ingestion Pipeline\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee4be6",
   "metadata": {},
   "source": [
    "### Milestone 2: Data Ingestion Pipeline\n",
    "### Step 1: Handle Missing Values\n",
    "\n",
    "Before performing data transformations or model training, itâ€™s essential to handle missing values to maintain data quality and prevent model bias.\n",
    "This step fills missing numerical values with their mean and categorical values with their mode to ensure consistent and complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87669271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filling NA values:\n",
      " Number_of_Riders           0\n",
      "Number_of_Drivers          0\n",
      "Location_Category          0\n",
      "Customer_Loyalty_Status    0\n",
      "Number_of_Past_Rides       0\n",
      "Average_Ratings            0\n",
      "Time_of_Booking            0\n",
      "Vehicle_Type               0\n",
      "Expected_Ride_Duration     0\n",
      "Historical_Cost_of_Ride    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dynamic_pricing.csv\")\n",
    "#Handle Missing Values\n",
    "# Fill missing numerical with mean\n",
    "for col in df.select_dtypes(include=np.number).columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# Fill missing categorical with mode\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(\"\\nAfter filling NA values:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16089b",
   "metadata": {},
   "source": [
    "### Milestone 2: Data Ingestion Pipeline\n",
    "####  step 2: Export Cleaned Dataset to CSV\n",
    "\n",
    "After handling missing values and performing necessary preprocessing, the cleaned dataset is exported as a CSV file for downstream tasks such as feature engineering and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbfa1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned dataset saved as dynamic_pricing_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#Cleaned the csv sheet\n",
    "df.to_csv(\"dynamic_pricing_cleaned.csv\", index=False)\n",
    "print(\" Cleaned dataset saved as dynamic_pricing_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26914032",
   "metadata": {},
   "source": [
    "###  Milestone 2: Data Ingestion Pipeline\n",
    "\n",
    "####  Step 1â€“4: Data Cleaning and Preprocessing Pipeline\n",
    "\n",
    "In **Milestone 2: Data Ingestion Pipeline**, the goal is to automate the **data ingestion and preprocessing** workflow â€” ensuring clean, reliable input for model training and dashboard analytics.  \n",
    "This step creates a modular pipeline to **load, clean, encode, and store** the processed dataset, ready for feature engineering and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044cc743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded successfully: 1000 rows, 10 columns\n",
      "âœ… Missing values handled.\n",
      "âœ… Categorical columns encoded.\n",
      "âœ… Cleaned data saved as cleaned_csv_data.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_data(file_path, save_path=\"cleaned_csv_data.csv\"):\n",
    "    \"\"\"Compound function: loads, cleans, encodes, and saves dataset.\"\"\"\n",
    "    \n",
    "    # Step 1: Load dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"âœ… Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "    # Step 2: Handle missing values\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    print(\"âœ… Missing values handled.\")\n",
    "\n",
    "    # Step 3: Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    print(\"âœ… Categorical columns encoded.\")\n",
    "\n",
    "    # Step 4: Save the cleaned dataset\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"âœ… Cleaned data saved as {save_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ðŸš€ Run the compound pipeline\n",
    "file_path = \"dynamic_pricing.csv\"\n",
    "df_cleaned = preprocess_data(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
