{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b250adda",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"color:#1F618D;\">Milestone 1: Requirements & Data Preparation</h2>\n",
    "<h3 style=\"color:#2874A6;\">Step 1: Data Loading and Initial Exploration</h3>\n",
    "\n",
    "<p style=\"font-size:15px;\">As part of the data ingestion and preparation phase, it begins by importing the required Python libraries and loading the dataset for analysis.\n",
    "The dataset is sourced from <b>Kaggle Dynamic Pricing Dataset</b> and <b>Statso Case Study</b>, containing historical sales, pricing, and inventory information.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dynamic_pricing.csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nData Types:\\n\", df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828565",
   "metadata": {},
   "source": [
    "\n",
    "**Sample Output:**  \n",
    "```\n",
    "Shape: (1000, 10)\n",
    "\n",
    "Data Types:\n",
    " Number_of_Riders             int64\n",
    "Number_of_Drivers            int64\n",
    "Location_Category           object\n",
    "Customer_Loyalty_Status     object\n",
    "Number_of_Past_Rides         int64\n",
    "Average_Ratings            float64\n",
    "Time_of_Booking             object\n",
    "Vehicle_Type                object\n",
    "Expected_Ride_Duration       int64\n",
    "Historical_Cost_of_Ride    float64\n",
    "dtype: object\n",
    "\n",
    "First 5 rows:\n",
    "    Number_of_Riders  Number_of_Drivers Location_Category  Customer_Loyalty_Status  Number_of_Past_Rides  Average_Ratings  Time_of_Booking  Vehicle_Type  Expected_Ride_Duration  Historical_Cost_of_Ride\n",
    "0                90                 45             Urban                  Silver                    13             4.47           Night      Premium                      90               284.257273\n",
    "1                58                 39          Suburban                  Silver                    72             4.06         Evening      Economy                      43               173.874753\n",
    "2                42                 31             Rural                  Silver                     0             3.99       Afternoon      Premium                      76               329.795469\n",
    "3                89                 28             Rural                 Regular                    67             4.31       Afternoon      Premium                     134               470.201232\n",
    "4                78                 22             Rural                 Regular                    74             3.77       Afternoon      Economy                     149               579.681422\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb9c88",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style=\"color:#2874A6;\">Step 3: Handle Categorical Variables (Encoding)</h3>\n",
    "<p style=\"font-size:15px;\">Before model training, all categorical (text-based) features in the dataset must be converted into numerical form. This ensures that machine learning algorithms such as XGBoost, LightGBM, and other advanced models can process the data effectively.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_enc = LabelEncoder()\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = label_enc.fit_transform(df[col])\n",
    "\n",
    "print(\"Categorical variables encoded\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6652b",
   "metadata": {},
   "source": [
    "\n",
    "**Sample Output:**  \n",
    "```\n",
    "Categorical variables encoded\n",
    "   Number_of_Riders  Number_of_Drivers  Location_Category  Customer_Loyalty_Status  Number_of_Past_Rides  Average_Ratings  Time_of_Booking  Vehicle_Type  Expected_Ride_Duration  Historical_Cost_of_Ride\n",
    "0                90                 45                  2                        2                    13             4.47                3             1                      90               284.257273\n",
    "1                58                 39                  1                        2                    72             4.06                1             0                      43               173.874753\n",
    "2                42                 31                  0                        2                     0             3.99                0             1                      76               329.795469\n",
    "3                89                 28                  0                        1                    67             4.31                0             1                     134               470.201232\n",
    "4                78                 22                  0                        1                    74             3.77                0             0                     149               579.681422\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c9615",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style=\"color:#2874A6;\">Step 4: Save Cleaned and Encoded Dataset</h3>\n",
    "<p style=\"font-size:15px;\">After completing all preprocessing steps — including missing value handling and encoding — the cleaned dataset is saved for later use in feature engineering and model training.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"cleaned_csv_data.csv\", index=False)\n",
    "print(\"Cleaned dataset saved as 'cleaned_csv_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b5b2f",
   "metadata": {},
   "source": [
    "\n",
    "**Output:**  \n",
    "```\n",
    "Cleaned dataset saved as 'cleaned_csv_data.csv'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c74fe",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style=\"color:#2874A6;\">Step 5: Basic Data Loading and Cleaning Pipeline</h3>\n",
    "<p style=\"font-size:15px;\">To ensure a standardized, reproducible data preparation process, a machine learning pipeline is constructed using Scikit-learn’s <b>Pipeline</b> and <b>ColumnTransformer</b> modules. This automates missing value handling, scaling of numerical data, and consistent categorical imputation.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = []  # already encoded\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(\"Pipeline applied successfully!\")\n",
    "print(\"Processed data shape:\", X_processed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141dd3b",
   "metadata": {},
   "source": [
    "\n",
    "**Output:**  \n",
    "```\n",
    "Pipeline applied successfully!\n",
    "Processed data shape: (1000, 10)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}